{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. predict the unlabeled data (Naive Bayes, SVM)\\n2. evaluate the accuracy,f1,ruc,etc?? (check with the doc later)\\n3. Topic Modeling\\n4. wordcloud(maybe,if applicable)\\n5. visualization(maybe, if applicable)\\n6. think about some other fun questions about this data set\\n7. paper \\n    Exploring the Use of Text Classification in the Legal Domain - arXiv\\n    https://arxiv.org/pdf/1710.09306\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "\"\"\"\n",
    "1. predict the unlabeled data (Naive Bayes, SVM)\n",
    "2. evaluate the accuracy,f1,ruc,etc?? (check with the doc later)\n",
    "3. Topic Modeling\n",
    "4. wordcloud(maybe,if applicable)\n",
    "5. visualization(maybe, if applicable)\n",
    "6. think about some other fun questions about this data set\n",
    "7. paper \n",
    "    Exploring the Use of Text Classification in the Legal Domain - arXiv\n",
    "    https://arxiv.org/pdf/1710.09306\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string \n",
    "import nltk\n",
    "import re \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judgements</th>\n",
       "      <th>Area.of.Law</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LNIND_1988_CAL_114</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LNIND_1956_CAL_163</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LNIND_1976_CAL_277</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LNIND_1980_CAL_52</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LNIND_1955_CAL_124</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>LNIND_1993_DEL_112</td>\n",
       "      <td>Criminal Laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>LNIND_1988_CAL_83</td>\n",
       "      <td>Service Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>LNIND_1993_DEL_16</td>\n",
       "      <td>Criminal Laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>LNIND_1957_CAL_46</td>\n",
       "      <td>Succession Laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>LNIND_1954_CAL_141</td>\n",
       "      <td>Government Contracts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Judgements           Area.of.Law\n",
       "0    LNIND_1988_CAL_114          To be Tested\n",
       "1    LNIND_1956_CAL_163          To be Tested\n",
       "2    LNIND_1976_CAL_277          To be Tested\n",
       "3     LNIND_1980_CAL_52          To be Tested\n",
       "4    LNIND_1955_CAL_124          To be Tested\n",
       "..                  ...                   ...\n",
       "994  LNIND_1993_DEL_112         Criminal Laws\n",
       "995   LNIND_1988_CAL_83           Service Law\n",
       "996   LNIND_1993_DEL_16         Criminal Laws\n",
       "997   LNIND_1957_CAL_46       Succession Laws\n",
       "998  LNIND_1954_CAL_141  Government Contracts\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look on the labels' file\n",
    "mapping = pd.read_csv('data/Interview_Mapping.csv')\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# create labels\n",
    "unlabeled = []\n",
    "labeled = []\n",
    "labels = []\n",
    "\n",
    "for index,row in mapping.iterrows():\n",
    "    if row['Area.of.Law'] == 'To be Tested':\n",
    "        unlabeled.append(row['Judgements'])\n",
    "    else: \n",
    "        labeled.append(row['Judgements'])\n",
    "        labels.append(row['Area.of.Law'])\n",
    "        \n",
    "# how much unique area of law        \n",
    "print(len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "import os\n",
    "\n",
    "unlabeled_text=[]\n",
    "labeled_text=[]\n",
    "\n",
    "for name in unlabeled:\n",
    "    path = os.path.join('data/',name+'.txt')\n",
    "    with open(path,'r',errors = 'ignore') as f:\n",
    "        unlabeled_text.append(f.read())\n",
    "for name in labeled:\n",
    "    path = os.path.join('data/',name+'.txt')\n",
    "    with open(path,'r',errors = 'ignore') as f:\n",
    "        labeled_text.append(f.read())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labeled_text[] each of the element in this array is a passage\n",
    "and what i need to do is to clean each of the passage first \n",
    "and combine the cleaned passages together into a new array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'party mahamaya banerjee versus state high court judicature calcutta judge honourable mr justice monoj kumar mukherjee amp honourable mr justice s ganguly suit appeal no doj advocate appearedfor appearing party bhaskar ghoshbimal kumar chatterjeedp majumdarsaktinath mukherjeeadvocates judgment monoj kumar mukherjee j gita banerjee predecessorininterest opposite party filed petition suit title suit no third court subordinate judge assistant district judge howrah sister petitioner herein claiming moiety share suit property nonappearance petitioner suit decreed ex parte preliminary form january march petitioner learned advocate sri sachin mukherjee filed application pvorder rule pv lgcode civil procedure lg code short setting aside ex parte decree registered misc case no july the petitioner filed another application said advocate prayer drawing another preliminary decree setting aside ex parte decree earlier passed taking consideration fact pursuant deed settlement executed father august sister entitled rd rd share respectively suit property april misc case taken hearing petitioner filed application advocate stating view earlier application dated july praying second preliminary decree find expedient proceed misc case further learned judge accordingly dismissed misc case nonprosecution order no dated april application dated july also rejected learned judge order no dated august finding wholly misconceived application review order filed petitioner october application registered misc case no june petitioner filed another application advocate stating alienated right title interest suit property meantime wish proceed suit view submission learned judge dismissed misc case no order no dated june fc thereafter petitioner filed application section code july another advocate engaged praying review order no dated june application petitioner averred inter alia old illiterate lady aware provision law implication ex parte preliminary decree owing wrong legal advice erstwhile advocate filed misconceived application allowed misc case dismissed accordingly prayed setting aside order dated june reviewing same another application thereafter filed amend application section code include averment misc case no restore otherwise would suffer irreparable loss injury prayer setting aside order dated april dismissing misc case opposite party contested application filing written objection support averment application the petitioner examined sri sachin mukherjee advocate earlier engaged her order no date december learned judge dismissed application matter application amendment aggrieved thereby petitioner filed present revisional application heard contested onefc considered nature content various application filed petitioner learned advocate sri sachin mukherjee hesitation concluding petitioner wrongly advised him particularly filing application drawing another preliminary decree setting aside ex parte decree earlier passed prosecuting application earlier filed or r c p c elementary knowledge long decree either preliminary final legally subsists cannot replaced substituted another decree necessarily follows ex parte preliminary decree tile instant suit set aside allowing application order rule code another preliminary decree could passed therefore filing application pentitioner expressing intention proceed misc case no filed application substitution preliminary decree wholly misconceived must attributed wrong advice learned advocate making observation drawn inspiration sworn testimony learned advocate admitted step taken proper application filed bona fide mistake fact therefore fully satisfied petitioner badly let wrong advice given former advocate placed unenviable position hd impugned order find learned judge appreciated predicament petitioner rejected application solely ground phrase sufficient reason order rule code include misconception fact andor law advocate inherent power could used correct erroneous view learned advocate are however unable agree learned judge though application filed section code along amendment petitioner prayed setting aside order dated june rejecting application review order dated april dismissing misc case registered application order rule code reviewing two order application instituted one order rule code fact considering nature relief sought rule manner application fact circumstance instant case already noticed principal ground canvassed setting aside order whatever step taken earlier connection suit wrong advice advocate already noticed testimony learned advocate also support view filing application therefore petitioner prayed justice denied owing patently wrong step taken legal advice situation court would failing duty invoke inherent power come rescue every court function purpose justice according law therefore shall deemed posse necessary corollary thereto power may necessary right undo wrong course functioning exercise inherent power provoked necessity operational field sphere neither well defined circumscribed also desirable put wholesome salutary power straitjacket therefore long trammelled trampled express statutory provision inherent power may invoke exercised meet judicial exigency absence tiny legislative inhibition exercise inherent power fact circumstance case we therefore allow application section code civil procedure amended set aside no dated april dismissing misc case learned trial judge hereby directed proceed misc case accordance law view of direction order necessary respect misc case hd revisional application thus allowed without order cost sudhanshu sekhar ganguly j agree dpapplication alloweddp'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "punct = string.punctuation\n",
    "\n",
    "labeled_cleaned=[]\n",
    "unlabeled_cleaned = []\n",
    "\n",
    "for passage in labeled_text:\n",
    "    # remove links \n",
    "    passage= re.sub(r'http(s)?:\\/\\/\\S*', \"\", str(passage))\n",
    "    # remove \\n\n",
    "    passage = ''.join([elem.replace('\\n',' ') for elem in passage])\n",
    "    # normalization and remove stopwords\n",
    "    passage = ' '.join([elem for elem in passage.lower().split() if elem not in stop])\n",
    "    #remove punctuation \n",
    "    passage = ''.join([elem.replace('[^\\w\\s]',' ') for elem in passage if elem not in punct])\n",
    "    #remove digits\n",
    "    passage = ''.join([elem for elem in passage if not elem.isdigit()])\n",
    "    #lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    passage = ' '.join(lemmatizer.lemmatize(elem) for elem in passage.split())\n",
    "    \n",
    "    labeled_cleaned.append(passage)\n",
    "\n",
    "    \n",
    "for passage in unlabeled_text:\n",
    "        \n",
    "    # remove links \n",
    "    passage= re.sub(r'http(s)?:\\/\\/\\S*', \"\", str(passage))\n",
    "    # remove \\n\n",
    "    passage = ''.join([elem.replace('\\n',' ') for elem in passage])\n",
    "    # normalization and remove stopwords\n",
    "    passage = ' '.join([elem for elem in passage.lower().split() if elem not in stop])\n",
    "    #remove punctuation \n",
    "    passage = ''.join([elem.replace('[^\\w\\s]',' ') for elem in passage if elem not in punct])\n",
    "    #remove digits\n",
    "    passage = ''.join([elem for elem in passage if not elem.isdigit()])\n",
    "    #lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    passage = ' '.join(lemmatizer.lemmatize(elem) for elem in passage.split())\n",
    "\n",
    "    unlabeled_cleaned.append(passage)\n",
    "    # it has to be a string so it could be processed later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?bc?bc?bc'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the labeled data into training and validation set \n",
    "# use 7-3 \n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_text,val_text,train_labels,val_labels =train_test_split(labeled_cleaned,labels,test_size = 0.3,random_state = 0)\n",
    "\n",
    "# do tfidf to get X_train and X_val\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_text)\n",
    "X_val = vectorizer.transform(val_text)\n",
    "\n",
    "# do label encoding to get y_train and y_val\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "y_train = encoder.transform(train_labels)\n",
    "y_val = encoder.transform(val_labels)\n",
    "all_labels = encoder.classes_\n",
    "\n",
    "# do tfidf to get X_test (unlabeled text that needed to be predicted)\n",
    "X_test = vectorizer.transform(unlabeled_cleaned) #transform on test set, not fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.32592592592592595\n",
      "[ 6  6  6  6  6  6  6  6 23  6 23  6 23 39  6  6  6 39  6  6 23 23  6  6\n",
      " 39  6 23  6 39 23  6 39  6 23  6 14  6  6  6  6  6  6  6 23  6  6  6  6\n",
      " 39  6  6 39 39  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 23\n",
      "  6  6  6  6 23  6  6  6  6 23  6 39  6  6  6  6  6 23 39 23 23  6  6  6\n",
      " 23  6  6  6]\n",
      "Train accuracy :  0.3640699523052464\n",
      "Test accuracy :   0.32592592592592595\n"
     ]
    }
   ],
   "source": [
    "# use Naive Bayes\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "modelNB = naive_bayes.MultinomialNB()\n",
    "modelNB.fit(X_train,y_train)\n",
    "predicted_labels = modelNB.predict(X_val)\n",
    "print('f1 score: ',f1_score(y_val,predicted_labels,average='micro'))\n",
    "result = modelNB.predict(X_test)\n",
    "print(result)\n",
    "\n",
    "yHat_train = modelNB.predict(X_train)\n",
    "yHat_val = modelNB.predict(X_val)\n",
    "\n",
    "print(\"Train accuracy : \", accuracy_score(y_train, yHat_train))\n",
    "print(\"Test accuracy :  \", accuracy_score(y_val, yHat_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.2777777777777778\n",
      "[ 6  6  6  6  6  6  6  6 23  6  6  6 23  6  6  6  6  6  6  6 23 23  6  6\n",
      "  6  6 23  6  6  6  6  6  6 23  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6 39  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6 23  6  6  6  6  6  6  6  6  6  6  6  6 23  6 23 23  6  6  6\n",
      " 23  6  6  6]\n",
      "Train accuracy :  0.2670906200317965\n",
      "Test accuracy :   0.2777777777777778\n"
     ]
    }
   ],
   "source": [
    "# use SVM\n",
    "from sklearn import svm\n",
    "\n",
    "modelSVM = svm.SVC(kernel='linear',C=0.1)\n",
    "modelSVM.fit(X_train,y_train)\n",
    "predicted_labels = modelSVM.predict(X_val)\n",
    "print('f1 score: ',f1_score(y_val,predicted_labels,average='micro'))\n",
    "result = modelSVM.predict(X_test)\n",
    "print(result)\n",
    "\n",
    "yHat_train = modelSVM.predict(X_train)\n",
    "yHat_val = modelSVM.predict(X_val)\n",
    "\n",
    "print(\"Train accuracy : \", accuracy_score(y_train, yHat_train))\n",
    "print(\"Test accuracy :  \", accuracy_score(y_val, yHat_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.562962962962963\n",
      "[34  6  6 14 14  6  6 28 23  6 23  6 23 39  6 14  6 39 37  6 23 23 28  6\n",
      " 39  6 23  6 39 36  6 39  6 23 34 14  1  6 14 15  6  6 13 23  6 34 14  6\n",
      " 39 14 13 39 39  6  1 28  1 23  6  6 34 14 39 13 34  6  6  6  6 14  6 36\n",
      "  6  6 37  6 23 14  6 14  6  7  6 39  6 39 34 37  6 23 39 23 23 14  6  6\n",
      " 23  6 13  6]\n",
      "Train accuracy :  0.7329093799682035\n",
      "Test accuracy :   0.562962962962963\n"
     ]
    }
   ],
   "source": [
    "# use Linear Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(X_train,y_train)\n",
    "predicted_labels = modelLR.predict(X_val)\n",
    "print('f1 score: ',f1_score(y_val,predicted_labels,average='micro'))\n",
    "result = modelLR.predict(X_test)\n",
    "print(result)\n",
    "yHat_train = modelLR.predict(X_train)\n",
    "yHat_val = modelLR.predict(X_val)\n",
    "\n",
    "print(\"Train accuracy : \", accuracy_score(y_train, yHat_train))\n",
    "print(\"Test accuracy :  \", accuracy_score(y_val, yHat_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Judgements\\tArea of Law\n",
      "0        LNIND_1988_CAL_114\\tProperty Laws\n",
      "1      LNIND_1956_CAL_163\\tCivil Procedure\n",
      "2      LNIND_1976_CAL_277\\tCivil Procedure\n",
      "3    LNIND_1980_CAL_52\\tCriminal Procedure\n",
      "4   LNIND_1955_CAL_124\\tCriminal Procedure\n",
      "..                                     ...\n",
      "95     LNIND_1980_CAL_279\\tCivil Procedure\n",
      "96          LNIND_1980_CAL_229\\tIncome Tax\n",
      "97     LNIND_1988_CAL_232\\tCivil Procedure\n",
      "98       LNIND_1957_CAL_142\\tCriminal Laws\n",
      "99     LNIND_1988_CAL_107\\tCivil Procedure\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# write result in csv\n",
    "with open('predictions.csv','w') as f:\n",
    "    f.write('Judgements' + '\\t' + 'Area of Law' + '\\n')\n",
    "    predictionList = all_labels[result]\n",
    "    for i in range(0, len(result)):\n",
    "        f.write(unlabeled[i] + '\\t' + predictionList[i] + '\\n')\n",
    "        \n",
    "sss = pd.read_csv('predictions.csv')\n",
    "print(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Judgements\\tArea of Law\n",
      "0        LNIND_1988_CAL_114\\tProperty Laws\\t\n",
      "1      LNIND_1956_CAL_163\\tCivil Procedure\\t\n",
      "2      LNIND_1976_CAL_277\\tCivil Procedure\\t\n",
      "3    LNIND_1980_CAL_52\\tCriminal Procedure\\t\n",
      "4   LNIND_1955_CAL_124\\tCriminal Procedure\\t\n",
      "..                                       ...\n",
      "95     LNIND_1980_CAL_279\\tCivil Procedure\\t\n",
      "96          LNIND_1980_CAL_229\\tIncome Tax\\t\n",
      "97     LNIND_1988_CAL_232\\tSuccession Laws\\t\n",
      "98       LNIND_1957_CAL_142\\tCriminal Laws\\t\n",
      "99     LNIND_1988_CAL_107\\tCivil Procedure\\t\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taaa\tbbb\t\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
