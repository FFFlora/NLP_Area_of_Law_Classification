{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. predict the unlabeled data (Naive Bayes, SVM) XGBoost\\n2. evaluate the accuracy ✓\\n3. Topic Modeling\\n4. wordcloud(maybe,if applicable)\\n5. visualization(maybe, if applicable)\\n6. think about some other fun questions about this data set\\n7. paper \\n    Exploring the Use of Text Classification in the Legal Domain - arXiv\\n    https://arxiv.org/pdf/1710.09306\\n8. reproducible     \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "\"\"\"\n",
    "1. predict the unlabeled data (Naive Bayes, SVM) XGBoost\n",
    "2. evaluate the accuracy ✓\n",
    "3. Topic Modeling\n",
    "4. wordcloud(maybe,if applicable)\n",
    "5. visualization(maybe, if applicable)\n",
    "6. think about some other fun questions about this data set\n",
    "7. paper \n",
    "    Exploring the Use of Text Classification in the Legal Domain - arXiv\n",
    "    https://arxiv.org/pdf/1710.09306\n",
    "8. reproducible     \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string \n",
    "import nltk\n",
    "import re \n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,classification_report\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judgements</th>\n",
       "      <th>Area.of.Law</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LNIND_1988_CAL_114</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LNIND_1956_CAL_163</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LNIND_1976_CAL_277</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LNIND_1980_CAL_52</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LNIND_1955_CAL_124</td>\n",
       "      <td>To be Tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>LNIND_1993_DEL_112</td>\n",
       "      <td>Criminal Laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>LNIND_1988_CAL_83</td>\n",
       "      <td>Service Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>LNIND_1993_DEL_16</td>\n",
       "      <td>Criminal Laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>LNIND_1957_CAL_46</td>\n",
       "      <td>Succession Laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>LNIND_1954_CAL_141</td>\n",
       "      <td>Government Contracts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Judgements           Area.of.Law\n",
       "0    LNIND_1988_CAL_114          To be Tested\n",
       "1    LNIND_1956_CAL_163          To be Tested\n",
       "2    LNIND_1976_CAL_277          To be Tested\n",
       "3     LNIND_1980_CAL_52          To be Tested\n",
       "4    LNIND_1955_CAL_124          To be Tested\n",
       "..                  ...                   ...\n",
       "994  LNIND_1993_DEL_112         Criminal Laws\n",
       "995   LNIND_1988_CAL_83           Service Law\n",
       "996   LNIND_1993_DEL_16         Criminal Laws\n",
       "997   LNIND_1957_CAL_46       Succession Laws\n",
       "998  LNIND_1954_CAL_141  Government Contracts\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look on the labels' file\n",
    "mapping = pd.read_csv('data/Interview_Mapping.csv')\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# create labels\n",
    "unlabeled = []\n",
    "labeled = []\n",
    "labels = []\n",
    "\n",
    "for index,row in mapping.iterrows():\n",
    "    if row['Area.of.Law'] == 'To be Tested':\n",
    "        unlabeled.append(row['Judgements'])\n",
    "    else: \n",
    "        labeled.append(row['Judgements'])\n",
    "        labels.append(row['Area.of.Law'])\n",
    "        \n",
    "# how much unique area of law        \n",
    "print(len(set(labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "\n",
    "unlabeled_text=[]\n",
    "labeled_text=[]\n",
    "\n",
    "for name in unlabeled:\n",
    "    path = os.path.join('data/',name+'.txt')\n",
    "    with open(path,'r',errors = 'ignore') as f:\n",
    "        unlabeled_text.append(f.read())\n",
    "for name in labeled:\n",
    "    path = os.path.join('data/',name+'.txt')\n",
    "    with open(path,'r',errors = 'ignore') as f:\n",
    "        labeled_text.append(f.read())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labeled_text[] each of the element in this array is a passage\n",
    "and what i need to do is to clean each of the passage first \n",
    "and combine the cleaned passages together into a new array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lg west bengal land requisition acquisition lg pv section pv party howrah mill limited versus state west bengal high court judicature calcutta judge honourable mr justice bhagabati prasad banerjee cr w doj advocate appeared appearing party anindya kumar mitra lakshmi kumar gupta prabir roy chaudhary sankar ghosh sefali sarkar smriti kana mukherjee somnath chatterji advocate judgment bhagabati prasad banerjee j fcwrit application moved petitioner company challenging order requisition no dated r h july annexure b writ petition provision subsection section west bengal land requisition acquisition act additional district magistrate howrah requisitioned property question already occupation mesrs remington rand india ltd respondent no herein purpose providing proper facility maintaining supply service essential life community creating employment opportunity peoplefc fact relevant purpose case short follows registered deed lease dated th september petitioner company owner of jute mill shibpur howrah granted lease portion mill promise favour respondent no remington rand india ltd term year begining let september expired effect st september monthly rent r expiry said lease period year petitioner company notice dated th february required respondent no remington rand india ltd deliver peaceful vacant possession said premise petitioner company expiry period stipulated deed lease dated th september lease periodexpired effect st september respondent company deliver possession said premise thereafter st april petitioner company filed suit eviction respondent company title suit no court subordinate judge howrah upon petitioner application made high court clause letter patent transfer said suit honble court said suit transferred court expeditious hearing basis allegation respondent delaying final hearing said suit plea other th may said suit appeared final hearing day respondent company moved application amendment written statement said amendment allowed lordship honble mr justice b c basak court matter directed listed th june date course hearing said amendment application lordship honble mr justice b c basak court enquired party whether suit could settled party agreeing upon grant fresh demise favour respondent company enhanced rate rent fixed regard market rate matter adjourned effecting settlement party thereafter respondent company offered term settlement petitioner company petitioner company could agree according petitioner company respondent intention pay market rate rent said premise respondent company wanted continue occupation premise old rate rent fixed year stated petitioner company respondent company flourishing concern available profit taxation year ending st march r lakh net profit r lakh stated respondent company offered dividend period rate suit adjourned effecting compromise party order requisition served upon petitioner company continuing occupation premise question respondent company order requisition challenge fcpetitioner company challenged validity order requisition ground order requisition could passed provision impugned act purpose specifically mentioned legislature fulfilled fcor word purpose fulfillment purpose specified act property could requisitioned stated order requisition passed basis formation opinion necessary purpose providing proper facility maintaining supply service essential life community creating employment opportunity people alleged dispute respondent company whose benefit order requisition issued engaged manufacturing typewriter machine contended typewriter machine cannot said thing necessary maintaining supply service essential life community word supply service essential life community got meaning meaning expression could enlarged bring within fold matter thing strictly supply service essential life community is stated provision said act requisition could made private company connection reference made provision land acquisition act particularly part vi thereof provides mode acquisition property provision land acquisition act purpose company one prerequisite acquiring property company company must bonafide attempt purchase said property secondly acquisition could made public purpose stated order requisition could passed impugned act made speedy requisition property meet urgent situation connected supply service essential life community increasing employment opportunity people establishing commercial estate industrial estate andor proper facility transport communication irrigation drainage etc next submitted behalf petitioner company order requisition issued colourable exercise power law inasmuch a stated instant case admittedly lease period expired expiry lease period respondent company failed neglected deliver possession thereafter recovery possession suit filed pendency said suit attempt effecting compromise failed summary power requisition impugned act invoked solely purpose protecting company occupation premise question lessee lease expired failed deliver possession suit filed also refused pay market rate rent contrary invoking summary power requisition property requisitioned submitted petitioner company tine state government exercise emergency intended respondent company continue possession old rate cost petitioner company facing great financial crisis stated existence petitioner company stake submitted could public interest andor public purpose behind order requisition particularly view fact suit pending matter adjourned settlement interregnum period action taken impugned order requisition provided possession property question would taken delivered respondent company private company stated within scope said act face without jurisdiction without authority law stated though said order requisition land described schedule thereto would delivered respondent company th july taking possession p m th july order requisition delivered served petitioner company long p m th july submitted said order requisition would fulfill purpose mentioned act must held malafide foundation said order requisition nothing malice law contended behalf respondent company respondent company engaged manufacture typewriter machine arc demand typewriter country requisitioned land exists factory manufacture typewriter machine said company pay huge amount excise duty custom duty income tax sale tax number person already engaged factory case respondent company said requisition would help providing employment large number people said factory tremendous employment potentiality case state government said order requisition made providing andor continuing employment large number people without break industrial peace harmony continues sensative industrial area stated purpose requisition social need create continue employment potentiality state stated purpose order also uninterrupted industrial production ultimate benefit state way revenue coming production submitted tin order requisition could passed provision impugned act favour respondent company support thereof reliance placed division bench judgment court case dr bez boruah or v state west bengal or reported cwn state government acquired land calcutta electric supply corporation ltd whim engaged production distribution electricity admittedly supply essential life community reliance also placed decision supreme court case m girdhanlal son v balbir nath reported air sc support contention duty court give statute purposeful functional interpretation case held measure aimed social amelioration receive liberal beneficent construction case also held avoid patent injustice anamoly absurdity avoid invalidation law court would justified departing socalled golden rule constitution give effect object purpose enactment supplementing written word necessary order appreciate rival contention party necessary set provision section said act order requisition passed said section said act follows power requisition state government opinion necessary maintaining supply service essential life community increasing employment opportunity industrial estate different area providing proper facility transport communication irrigation drainage creation better living condition rural urban area industrial area excluded state government notification behalf construction reconstruction dwelling place area purpose connected therewith incidental thereto state government may order writing requisition land may make order appears necessary expedient connection requisitioning provided land used purpose religious worship used educational charitable institution shall requisitioned section preamble impugned act follows whereas expedient provide requisition speedy acquisition land purpose maintaining supply service essential life community increasing employment opportunity people establishing commercial estate industrial estate different area providing proper facility transport communication irrigation drainage creation better living condition urban rural area construction reconstruction dwelling place area purpose connected therewith incidental thereto regard submission petitioner order requisition passed colourable exercise pretended power provision said act suit filed petitioner recovery possession pending concerned affidavit opposition behalf respondent no stated i state th may time minister charge land land reform department consultation chief minister west bengal decided behalf state west bengal requisition acquisition land measuring sq ft mentioned schedule notice dated th july creating employment opportunity people state west bengal said decision conveyed board board revenue date subsequently member board o revenue considered proposal forwarded commerce industry department west bengal minister charge secretary commerce industry department considered proposal acquiring said land financial implication appeal obtaining financial provision compensation paid petitioner asset decided appropriate department consented acquiring land would secure employment least employee state west bengal factory situated land mentioned schedule notice may mentioned th may suit filed petitioner respondent no appeared peremptory list date respondent no moved application amendment written statement said amendment allowed said date suit directed listed th june appears next date namely th may decision taken disclosed affidavit opposition may mentioned th may course hearing amendment application lordship honble mr justice b c basak court enquired whether suit could settled party agreeing upon grant fresh demise favour respondent company enhanced rate rent fixed regard market value appears mr justice b c basak directed respondent company try agreeing mutually upon new rate rent fresh lease directed petitioner company appear th june appears next date th may decision taken date decision significant made crystal clear point time matter pending settlement decision requisition property taken government question whether fact circumstance case made bonafide done public interest firmly established principle every activity government must public element must therefore informed reason guided public interest government cannot act arbitrarily instant case order decide question whether state government acted bonafide public interest matter look fact circumstance case decision taken government admittedly hdrespondent company lessee period lease expired expiry period lease petitioner company filed suit recovery possession dispute petitioner company contesting suit question compromising suit agreeing renew lease enhanced rent came consideration point time petitioner moved state government upon state government decided requisition property already occupation make suit fructuous continue private respondent occupation property done validate possession impugned requisition orderhd instant case admittedly power section said act exercised state government instance respondent no point time suit pending matter record respondent standing way earlier disposal suit precise reason suit transferred court speedy disposal th may the application amendment no allowed course hearing learned judge enquired whether matter could compromised revised term next date decision taken behalf state government crystal clear power section exercised admittedly make suit fructuous view proper part state respondent invoke provision section said act suit pending circumstance suggest action taken behalf bonafide regard next submission part petitioner fact circumstance case power section said act could invoked all inasmuch a condition precedent exercising power act wholly absent respondent company disclosed reason exercising power section said act stated requisition made creating employment opportunity people state west bengal order requisition lit stated said requisition made the purpose providing proper facility maintaining supply service essential life community creating employment opportunity people admittedly respondent no occupation property continuing manufacturing typewriter machine there first question calles consideration court whether typewriter machine required maintaining supply service essential life community word essential mean according black law dictionary indispensably necessary important highest degree requisite required continued existence thing typewriter machine required purpose typing use typewriter machine country well known question whether typewriter machine could said thing necessary maintaining supply service essential life community afraid cannot give wide meaning word would beyond scope object act word supply service essential life community cannot given wide meaning word statute interpreted manner carves intention legislature true perspective reading preamble said act abundantly clear power section could invoked purpose specifically mentioned therein difficult hold manufacture typewriter machine thing necessary maintaining supply service essential life community inasmuch a community whole could require type winter machine essential supply service community even easily freely available whether particular thing required maintaining supply service essential life community construed according need proper enjoyment life reference may made provision essential commodity act whereas certain food article treated essential community such foodstuff fuel and article required community whole essential commodity certainly cosmetic cannot said essential commodity word essential service meaning service essential fort people like water supply electricity supply milk hospital service etc without people large cannot normally go sundry service cannot said essential service instant case word supply service qualified word essential supply service cannot said essential unless shown indispensably necessary community accordingly hold typewriter machine cannot said thing necessary maintaining supply service essential life community provided section said act question is is whether said requisition could supported purpose mentioned section said actis also stated said order requisition issued also increasing employment opportunity people state requisition could made increasing commercial estate industrial estate different area order requisition could made increasing employment potentiality establishing commercial estate industrial estate instant case question establishing commercial estate industrial estate inasmuch a industry much existence continued existence power section said act exercised view fact none hdalternative clause available state respondent exercising power requisition section said act could invoked case purpose scheme act unable give meaning section said act would open flood gate respondent exercising power section every case power circumscribe statute power exercised purpose statute passed power got limit legislature thought fit power requisition could exercised limited case power exercised fulfill purpose enacted question creating employment opportunity people state case could arise all question may arise would happens order requisition passed admittedly respondent company solvent company occupation premise question lease since th september period lease expired th september respondent company knew law land unless lease renewed respondent company deliver possession also admitted fact respondent company occupation premise even expiry period lease far purpose recovery possession petitioner company filed title suit suit pending talk compromise begin time state government passed order requisition summary manner protect respondent company earring party statutory power exercised protect company liable evicted general law land suit pending view fact circumstance case highly improper part state respondent intervene exercise emergency power requisition manner done view wholly unjust contrary public policy protect erring party right continue possession suit recover possession pending view within scope ambit provision section said act state protection unauthorised occupant allow unauthorised occupant continue possession validating exercise statutory power sought done instant case incidentally may mentioned ordinarily law acquisition namely land acquisition act property could acquisitioned acquisition made company certain statutory requirement complied view statutory requirement cannot bypassed invoking summary emergency power tire impugned act impugned act could invoked specified purpose provision impugned act property could requisitioned situation andor purpose mentioned act fulfilled thereafter necessary keep property event the may acquired purpose act speedy requisition order meet situationhd instant case fact circumstance power exercised manner beyond scope section said act connection reference may made decision supreme court india case h d vora v state maharashtra reported air sc wherein held if government want take ever property indefinite period time government must acquire property cannot use power requisition achieving object power requisition exercise ably government public purpose transitory character public purpose premise required perennial permanent character inception order passed requisitioning premise case order requisition passed would fraud upon statute government would requesting premise really speaking want premise acquisition object taking premise transitory permanent character in instant case admitted position need respondent company permanent nature view principle laid supreme court open state government requisition property need admittedly permanent land acquisition act laid elaborate procedure acquisition land company permissible acquire property private company public purpose word public purpose defined provision land acquisition act laid condition andor restriction land could acquired company view hdproperty could requisitioned company bypassing provision laud land acquisition act one important condition acquisition land company land acquisition act provided rule land acquisition company rule provides whenever company make application government acquit ion land government must satisfied basis report collector company made best endeavour fund land locality suitable purpose acquisition lat company made reason able effort get land negotiation person interested therein payment reasonable price effort failed view land acquisition act andor rule framed laid elaborate inbuilt procedure cannot bypassed also throw light legislature never intended requisition land requisition act special procedure laid land acquisition act accordingly hold impugned requisition private company west bengal land acquisition requisition act void illegalhd another aspect matter scheme said act order section issued valid reason served upon owner occupier possession whereof taken date time fixed case property requisitioned notification andor issuing prior notice scheme act requisition would completed possession taken term notice instant case dispute notice requisition served upon petitioner company time mentioned order requisition over point raised petitioner whether property could requisitioned purpose already possession respondent word requisition mean taking seizure property government property the occupation respondent view hdproperty could requisitioned respondent made clear scheme th act andor provision act impugned act nowhere contemplates impugned act could invoked purpose validating possession respect respondent unauthorised occupanthd necessary decide question whether impugned act could invoked purpose necessary court refer case law cited behalf respondent much case property requisitioned purpose specified act instant case already held fact circumstance case hdpower section could invoked purpose invoked fall outside scope ambit provision section said act also hold basis material placed court material possession state government form requisite opinion required section said act must held said order requisition fact illegal issue without jurisdiction result thereof writ petition succeeds rule made absolute order requisition dated th july bearing no annexure b petition quashed writ nature certiorari issue quashing said order section said act dated th july writ nature mandamus issue commanding respondent give effect effect order requisition dated th july rule made absolute order cost rule made absolutehd']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "punct = string.punctuation\n",
    "\n",
    "def clean_text(uncleaned_text):\n",
    "    cleaned_text=[]\n",
    "    for passage in uncleaned_text:\n",
    "        # remove links \n",
    "        passage= re.sub(r'http(s)?:\\/\\/\\S*', \"\", str(passage))\n",
    "        # remove \\n\n",
    "        passage = ''.join([elem.replace('\\n',' ') for elem in passage])\n",
    "        # normalization and remove stopwords\n",
    "        passage = ' '.join([elem for elem in passage.lower().split() if elem not in stop])\n",
    "        #remove punctuation \n",
    "        passage = ''.join([elem.replace('[^\\w\\s]',' ') for elem in passage if elem not in punct])\n",
    "        #remove digits\n",
    "        passage = ''.join([elem for elem in passage if not elem.isdigit()])\n",
    "        #lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        passage = ' '.join(lemmatizer.lemmatize(elem) for elem in passage.split())\n",
    "        cleaned_text.append(passage)\n",
    "        return cleaned_text\n",
    "clean_text(labeled_text)\n",
    "clean_text(unlabeled_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the labeled data into training and validation set \n",
    "# use 7-3 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_text,val_text,train_labels,val_labels =train_test_split(labeled_cleaned,labels,test_size = 0.25,random_state = 0)\n",
    "\n",
    "# do tfidf to get X_train and X_val\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_text)\n",
    "X_val = vectorizer.transform(val_text)\n",
    "\n",
    "# do tfidf to get X_test (unlabeled text that needed to be predicted)\n",
    "X_test = vectorizer.transform(unlabeled_cleaned) #transform on test set, not fit_transform\n",
    "\n",
    "# do label encoding to get y_train and y_val\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "y_train = encoder.transform(train_labels)\n",
    "y_val = encoder.transform(val_labels)\n",
    "all_labels = encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to meature the results\n",
    "def get_metrics(y_val, y_predicted,yHat_train,y_train):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_val, y_predicted, pos_label=None, average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_val, y_predicted, pos_label=None, average='weighted')\n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_val, y_predicted, pos_label=None, average='weighted')\n",
    "    # true positives + true negatives/ total\n",
    "    accuracyTest = accuracy_score(y_val, y_predicted)\n",
    "    accuracyTrain = accuracy_score(y_train,yHat_train)\n",
    "    return accuracyTest,accuracyTrain, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  6  6  6  6  6  6  6 23  6 23  6 23 39  6  6  6 39  6  6 23 23  6  6\n",
      " 39  6 23  6 39 23  6 39  6 23  6 14  6  6  6  6  6  6  6 23  6  6  6  6\n",
      " 39  6  6 39 39  6  6  6  6  6  6  6 23  6  6  6  6  6  6  6  6  6  6 23\n",
      "  6  6  6  6 23  6  6  6  6 23  6 39  6  6  6  6  6 23 39 23 23  6  6  6\n",
      " 23  6  6  6]\n",
      "Test accuracy = 0.329, Train accuracy = 0.359,precision = 0.250, recall = 0.329, f1 = 0.214\n"
     ]
    }
   ],
   "source": [
    "# 1st model: Naive Bayes\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "def modelNB(X_train,y_train,X_val,X_test):\n",
    "    modelNB = naive_bayes.MultinomialNB()\n",
    "    modelNB.fit(X_train,y_train)\n",
    "    predicted_labels_ = modelNB.predict(X_val)\n",
    "    result_ = modelNB.predict(X_test)\n",
    "    print(result_)\n",
    "    yHat_train_ = modelNB.predict(X_train)\n",
    "    return predicted_labels_,result_,yHat_train_\n",
    "\n",
    "predicted_labels,result,yHat_train=modelNB(X_train,y_train,X_val,X_test)\n",
    "accuracyTest,accuracyTrain, precision, recall, f1 = get_metrics(y_val, predicted_labels,yHat_train,y_train)\n",
    "print(\"Test accuracy = %.3f, Train accuracy = %.3f,precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracyTest,accuracyTrain, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34 28  6  8 14  1  7 28 23  6 23 39 23 39  6 14 18 39 37 11 23 23 16  7\n",
      " 39 25 23  8 39 36 36 39 34 23 34 14  2 11 28 15 16  6 13 36 34 34 14 38\n",
      " 39 30 13 39 39 27  1 17  1 18  4 11 34 15 34 38 38 35 14 36  6  7 18 36\n",
      "  6 11 37  8 23 13 20 36  6  7  1 39  5 39 34 37 36 23 39 23 23 14 27 16\n",
      " 23 21 13  6]\n",
      "Test accuracy = 0.631, Train accuracy = 0.917,precision = 0.641, recall = 0.631, f1 = 0.623\n"
     ]
    }
   ],
   "source": [
    "# 2nd model: Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def modelLR(X_train,y_train,X_val,X_test):\n",
    "    modelLR = LogisticRegression(C=3.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=0)\n",
    "    modelLR.fit(X_train,y_train)\n",
    "    predicted_labels_ = modelLR.predict(X_val)\n",
    "    result_ = modelLR.predict(X_test)\n",
    "    print(result_)\n",
    "    yHat_train_ = modelLR.predict(X_train)\n",
    "    return predicted_labels_,result_,yHat_train_\n",
    "\n",
    "predicted_labels,result,yHat_train=modelLR(X_train,y_train,X_val,X_test)\n",
    "accuracyTest,accuracyTrain, precision, recall, f1 = get_metrics(y_val, predicted_labels,yHat_train,y_train)\n",
    "print(\"Test accuracy = %.3f, Train accuracy = %.3f,precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracyTest,accuracyTrain, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3nd model: SVM\n",
    "# before applying SVMs,  standardize the data first.\n",
    "# Apply SVD, I chose 120 components. 120-200 components are good enough for SVM model.\n",
    "from sklearn import decomposition,preprocessing\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(X_train)\n",
    "X_train_svd = svd.transform(X_train)\n",
    "X_val_svd = svd.transform(X_val)\n",
    "X_test_svd=svd.transform(X_test)\n",
    "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(X_train_svd)\n",
    "X_train_svd_scl = scl.transform(X_train_svd)\n",
    "X_val_svd_scl = scl.transform(X_val_svd)\n",
    "X_test_svd_scl = scl.transform(X_test_svd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "Before SVD: \n",
      "Test accuracy = 0.182, Train accuracy = 0.141,precision = 0.033, recall = 0.182, f1 = 0.056\n",
      "[34  6  6 14  6  6  6 28 23  6 23 39 23 39  6 14  6 39 37  6 23 23  6  6\n",
      " 39  6 23  6 39 36 36 39 34 23 34 14  1 23 14 15 16  6 13 36  6 34 14  6\n",
      " 39 13 13 39 39  6  1 28  1  6  6  6  6  6 34 38 38  6  6 36  6  7  6 36\n",
      "  6  6 37  6 23 13 23 36  6  7  1 39  6 39 34 37 36 23 39 23 23 13  6  6\n",
      " 23 38 13  6]\n",
      "After SVD: \n",
      "Test accuracy = 0.573, Train accuracy = 0.866,precision = 0.521, recall = 0.573, f1 = 0.513\n"
     ]
    }
   ],
   "source": [
    "# use SVM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "def modelSVM(X_train,y_train,X_val,X_test):\n",
    "    modelSVM = svm.SVC(C=1.0,probability=True)\n",
    "    modelSVM.fit(X_train,y_train)\n",
    "    predicted_labels_ = modelSVM.predict(X_val)\n",
    "    result_ = modelSVM.predict(X_test)\n",
    "    print(result_)\n",
    "    yHat_train_ = modelSVM.predict(X_train)\n",
    "    return predicted_labels_,result_,yHat_train_\n",
    "\n",
    "predicted_labels,result,yHat_train=modelSVM(X_train,y_train,X_val,X_test)\n",
    "accuracyTest,accuracyTrain, precision, recall, f1 = get_metrics(y_val, predicted_labels,yHat_train,y_train)\n",
    "print(\"Before SVD: \\nTest accuracy = %.3f, Train accuracy = %.3f,precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracyTest,accuracyTrain, precision, recall, f1))\n",
    "\n",
    "\n",
    "predicted_labels_SVD,result_SVD,yHat_train_SVD =modelSVM(X_train_svd_scl,y_train,X_val_svd_scl,X_test_svd_scl)\n",
    "accuracyTest_SVD,accuracyTrain_SVD, precision_SVD, recall_SVD, f1_SVD = get_metrics(y_val, predicted_labels_SVD,yHat_train_SVD,y_train)\n",
    "print(\"After SVD: \\nTest accuracy = %.3f, Train accuracy = %.3f,precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracyTest_SVD,accuracyTrain_SVD, precision_SVD, recall_SVD, f1_SVD))\n",
    "\n",
    "# without truncatedSVD, the classifier was somehow underfit.\n",
    "# with truncatedSVD, the accuracy was raised dramatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 28  6  8 28  1 34 28 23  6 23 39 23 39  6 14 37 39 37 34 23 23 37  6\n",
      " 39  6 23  7 39  8 36 39  6 23 34 14  1 34 14 15 37  6 13 36  6 39 14  6\n",
      " 39 14 13 39 39  6  1  6  1 37  6  6 23 14 39 38 34 38 14 36 39 14 37 36\n",
      "  6  6 37  6 23 13  8 14  6  7  1 39 36 39 34 37 36 23 39 23 23 14  6 16\n",
      " 23 21 13  6]\n",
      "1\n",
      "Test accuracy = 0.613, Train accuracy = 0.929,precision = 0.552, recall = 0.613, f1 = 0.558\n"
     ]
    }
   ],
   "source": [
    "# 4th model: XgBoost\n",
    "\n",
    "import xgboost as xgb\n",
    "def modelxgb(X_train,y_train,X_val,X_test):\n",
    "    modelxgb = xgb.XGBClassifier(max_depth=6, n_estimators=200, colsample_bytree=0.5, \n",
    "                        subsample=0.5, nthread=10, learning_rate=0.01)\n",
    "    modelxgb.fit(X_train,y_train)\n",
    "    predicted_labels_ = modelxgb.predict(X_val)\n",
    "    result_ = modelxgb.predict(X_test)\n",
    "    print(result_)\n",
    "    yHat_train_ = modelxgb.predict(X_train)\n",
    "    return predicted_labels_,result_,yHat_train_\n",
    "\n",
    "# see the result on tfidf data \n",
    "predicted_labels,result,yHat_train = modelxgb(X_train,y_train,X_val,X_test)\n",
    "accuracyTest,accuracyTrain, precision, recall, f1 = get_metrics(y_val, predicted_labels,yHat_train,y_train)\n",
    "print(\"1\\nTest accuracy = %.3f, Train accuracy = %.3f,precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracyTest,accuracyTrain, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[34 28  6  8 28  1  4 28 23  6 23  6 23 39  6 14 18 39 37  6 23 23 37  7\n",
    " 39  6 23  7 39  8 36 39  6 23 37 14  2 34 14 15 37  8 13 36 34 34 14  6\n",
    " 39 30 13 39 39  6  2 17  2 18  6  6 23 34 39 38 34 38 14 36 39  7 18 36\n",
    " 27  6 37  6 23 13  8 14  6  7  1 39  6 39 38 37 36 23 39 23 23 13 27 16\n",
    " 23 21 13  6]\n",
    "Before SVD: \n",
    "Test accuracy = 0.618, Train accuracy = 1.000,precision = 0.599, recall = 0.618, f1 = 0.591\n",
    "\n",
    "[34 28  6  8 14  1  6 28 23  6 23 39 23 39  6 14  6 39  6 34 23 23 37  6\n",
    " 39  6 23 28 39 36 36 39  6 23 34 14  1 11 14 15 16  6 13 36 34 34 14 38\n",
    " 39 14 13 39 39 27  1 28  1 18  6 11 23 14 34 38 38  6 14  8 39 14  6 36\n",
    "  6  6  6  6 23 13  6 14  6  7  1 39 28  6 34 37 36 23 39 23 23 14  6 16\n",
    " 23 38 13  6]\n",
    "After SVD: \n",
    "Test accuracy = 0.569, Train accuracy = 1.000,precision = 0.522, recall = 0.569, f1 = 0.525\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_features(Vectorizer, model, n=5):\n",
    "    index_to_word = {v:k for k,v in Vectorizer.vocabulary_.items()}\n",
    "    \n",
    "    # loop for each class\n",
    "    classes ={}\n",
    "    for class_index in range(model.coef_.shape[0]):\n",
    "        word_importances = [(el, index_to_word[i]) for i,el in enumerate(model.coef_[class_index])]\n",
    "        sorted_coeff = sorted(word_importances, key = lambda x : x[0], reverse=True)\n",
    "        tops = sorted(sorted_coeff[:n], key = lambda x : x[0])\n",
    "        bottom = sorted_coeff[-n:]\n",
    "        classes[class_index] = {\n",
    "            'tops':tops,\n",
    "            'bottom':bottom\n",
    "        }\n",
    "    return classes\n",
    "\n",
    "importance_tfidf = get_most_important_features(vectorizer,modelLR,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_words(top_scores, top_words, bottom_scores, bottom_words, name):\n",
    "    y_pos = np.arange(len(top_words))\n",
    "    top_pairs = [(a,b) for a,b in zip(top_words, top_scores)]\n",
    "    top_pairs = sorted(top_pairs, key=lambda x: x[1])\n",
    "    \n",
    "    bottom_pairs = [(a,b) for a,b in zip(bottom_words, bottom_scores)]\n",
    "    bottom_pairs = sorted(bottom_pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_words = [a[0] for a in top_pairs]\n",
    "    top_scores = [a[1] for a in top_pairs]\n",
    "    \n",
    "    bottom_words = [a[0] for a in bottom_pairs]\n",
    "    bottom_scores = [a[1] for a in bottom_pairs]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))  \n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.barh(y_pos,bottom_scores, align='center', alpha=0.5)\n",
    "    plt.title('Irrelevant', fontsize=20)\n",
    "    plt.yticks(y_pos, bottom_words, fontsize=14)\n",
    "    plt.suptitle('Key words', fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.barh(y_pos,top_scores, align='center', alpha=0.5)\n",
    "    plt.title('Disaster', fontsize=20)\n",
    "    plt.yticks(y_pos, top_words, fontsize=14)\n",
    "    plt.suptitle(name, fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    plt.show()\n",
    "\n",
    "top_scores = [a[0] for a in importance_tfidf[1]['tops']]\n",
    "top_words = [a[1] for a in importance_tfidf[1]['tops']]\n",
    "bottom_scores = [a[0] for a in importance_tfidf[1]['bottom']]\n",
    "bottom_words = [a[1] for a in importance_tfidf[1]['bottom']]\n",
    "\n",
    "plot_important_words(top_scores, top_words, bottom_scores, bottom_words, \"Most important words for relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#try bag of word then tfidf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "train_text,val_text,train_labels,val_labels = train_test_split(labeled_cleaned,labels,test_size = 0.25,random_state = 0)\n",
    "X_train_count, count_vectorizer = cv(train_text)\n",
    "X_val_count = count_vectorizer.transform(val_text)\n",
    "\n",
    "# do tfidf to get X_test (unlabeled text that needed to be predicted)\n",
    "X_test_count = count_vectorizer.transform(unlabeled_cleaned) #transform on test set, not fit_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then do tfidf transformer to make training set and valid. set from occurences to freq.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tf = tfidf_transformer.fit_transform(X_train_count)\n",
    "X_val_tf = tfidf_transformer.transform(X_val_count)\n",
    "X_test_tf = tfidf_transformer.transform(X_test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34 28  6  8 14  1  7 28 23  6 23 39 23 39  6 14 18 39 37 11 23 23 16  7\n",
      " 39 25 23  8 39 36 36 39 34 23 34 14  2 11 28 15 16  6 13 36 34 34 14 38\n",
      " 39 30 13 39 39 27  1 17  1 18  4 11 34 15 34 38 38 35 14 36  6  7 18 36\n",
      "  6 11 37  8 23 13 20 36  6  7  1 39  5 39 34 37 36 23 39 23 23 14 27 16\n",
      " 23 21 13  6]\n",
      "Test accuracy = 0.631, Train accuracy = 0.917,precision = 0.641, recall = 0.631, f1 = 0.623\n"
     ]
    }
   ],
   "source": [
    "# see the result in model LR\n",
    "predicted_labels,result,yHat_train=modelLR(X_train_tf,y_train,X_val_tf,X_test_tf)\n",
    "accuracyTest,accuracyTrain, precision, recall, f1 = get_metrics(y_val, predicted_labels,yHat_train,y_train)\n",
    "print(\"Test accuracy = %.3f, Train accuracy = %.3f,precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracyTest,accuracyTrain, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the result in model XGBoost\n",
    "predicted_labels,result,yHat_train=modelxgb(X_train_tf,y_train,X_val_tf,X_test_tf)\n",
    "accuracyTest,accuracyTrain, precision, recall, f1 = get_metrics(y_val, predicted_labels,yHat_train,y_train)\n",
    "print(\"Test accuracy = %.3f, Train accuracy = %.3f,precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracyTest,accuracyTrain, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we setup a pipeline and do some grid search on LR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "text_clf_LR = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression( random_state=0) ),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__penalty': ('l1','l2'),\n",
    "    'clf__C': (0.01,0.1,1,3,10,100),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.01, 0.1, 1, 3, 10, 100),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed: 24.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1501.434s\n",
      "\n",
      "Best score: 0.620\n",
      "Best parameters set:\n",
      "\tclf__C: 100\n",
      "\tclf__penalty: 'l2'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(text_clf_LR, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in text_clf_LR.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(train_text, train_labels)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()  \n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_LR = Pipeline([('vect', CountVectorizer(max_df=1.0,ngram_range=(1,2))),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression(C=100,penalty='l2',random_state=0)),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6222222222222222"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_LR.fit(train_text, y_train)  \n",
    "predicted_ed2 = text_clf_LR.predict(val_text)\n",
    "np.mean(predicted_ed2 == y_val)    \n",
    "\n",
    "# which doesn't improve alot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try grid search on xgboost\n",
    "text_clf_xgb = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                     ('clf', xgb.XGBClassifier(random_state=0) ),\n",
    " ])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_depth': (3,9,15),\n",
    "    'clf__alpha': (0,0.1,0.5,1),\n",
    "    'clf__Eta':(0.01,0.015,0.05,0.1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__Eta': (0.01, 0.015, 0.05, 0.1),\n",
      " 'clf__alpha': (0, 0.1, 0.5, 1),\n",
      " 'clf__max_depth': (3, 9, 15),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(text_clf_xgb, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in text_clf_xgb.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(train_text, train_labels)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()  \n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# write result in csv\n",
    "with open('predictions.csv','w') as f:\n",
    "    f.write('Judgements' + '\\t' + 'Area of Law' + '\\n')\n",
    "    predictionList = all_labels[result]\n",
    "    for i in range(0, len(result)):\n",
    "        f.write(unlabeled[i] + '\\t' + predictionList[i] + '\\n')\n",
    "        \n",
    "sss = pd.read_csv('predictions.csv')\n",
    "print(sss)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic modeling for each class\n",
    "# Define a function that get text information for each class\n",
    "\n",
    "def get_text(inputs,outputList=[]):\n",
    "    '''\n",
    "    inputs must be a String type\n",
    "    '''\n",
    "    tempList=[]\n",
    "    for label in all_labels:\n",
    "        if (inputs==label):\n",
    "            tempList = mapping.loc[mapping['Area.of.Law']==inputs]\n",
    "            for name in tempList['Judgements']:\n",
    "                path = os.path.join('data/',name+'.txt')\n",
    "                with open(path,'r',errors = 'ignore') as f:\n",
    "                    outputList.append(f.read())\n",
    "            return outputList\n",
    "    return('Invalid Input')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of one of the topic, to do the topic modeling.\n",
    "get_text('Contract',outputList)\n",
    "cleaned_contr = clean_text(outputList)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/nlp-for-topic-modeling-summarization-of-legal-documents-8c89393b1534"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
